{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from math import sqrt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import os\n",
    "import json\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Execute the function with the defined parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "model_path  = \"model/\"\n",
    "fso_models_path = model_path  + \"fso_models.pkl\"\n",
    "rfl_models_path = model_path  +\"rfl_models.pkl\"\n",
    "train_data_path = model_path  +\"train_data.csv\"\n",
    "test_data_path = model_path  +\"test_data.csv\"\n",
    "best_params_fso_path = model_path  +\"best_params_fso.json\"\n",
    "best_params_rfl_path = model_path  + \"best_params_rfl.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading previously saved files...\n",
      "Successfully loaded saved models and data.\n"
     ]
    }
   ],
   "source": [
    "if (os.path.isfile(fso_models_path) and\n",
    "    os.path.isfile(rfl_models_path) and\n",
    "    os.path.isfile(train_data_path) and\n",
    "    os.path.isfile(test_data_path) and\n",
    "    os.path.isfile(best_params_fso_path) and\n",
    "    os.path.isfile(best_params_rfl_path)):\n",
    "    \n",
    "    print(\"Loading previously saved files...\")\n",
    "    # -- Load the objects --\n",
    "    fso_models = joblib.load(fso_models_path)\n",
    "    rfl_models = joblib.load(rfl_models_path)\n",
    "    \n",
    "    train_data = pd.read_csv(train_data_path)\n",
    "    test_data = pd.read_csv(test_data_path)\n",
    "    \n",
    "    with open(best_params_fso_path, \"r\") as fp:\n",
    "        best_params_fso = json.load(fp)\n",
    "    with open(best_params_rfl_path, \"r\") as fp:\n",
    "        best_params_rfl = json.load(fp)\n",
    "\n",
    "    rfl_table_final = pd.read_csv('rfl_table_final.csv')\n",
    "    fso_table_final=  pd.read_csv('fso_table_final.csv')    \n",
    "    \n",
    "    print(\"Successfully loaded saved models and data.\")\n",
    "\n",
    "else:\n",
    "    print(\"Saved files not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_selected_features(table):\n",
    "    \"\"\"\n",
    "    Finds the threshold index for selecting the most important features.\n",
    "    Extract features following the threshold index.\n",
    "    \"\"\" \n",
    "    feature_index = find_threshold(table)\n",
    "    # manuaually choose best features RFL specfic model (dust storm) based on feature selection performance plot\n",
    "    if feature_index>=23:\n",
    "        feature_index = 14\n",
    "        \n",
    "    selected_features = table['Removed_Feature'][feature_index:]\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "R2_TRESHOLD = 0.01\n",
    "RMSE_THRESHOLD = 0.02\n",
    "\n",
    "def find_threshold(data_table):\n",
    "    \"\"\"\n",
    "    Given a table containing the columns ['RMSE', 'R2'],\n",
    "    iterates row-by-row and finds the index where:\n",
    "       - The relative decrease in R² > R2_TRESHOLD\n",
    "       - AND the relative increase in RMSE > RMSE_THRESHOLD\n",
    "    Returns that row index or the last index if not found.\n",
    "    \"\"\"\n",
    "    for i in range(len(data_table) - 1):\n",
    "        r2_current = data_table['R2'].iloc[i]\n",
    "        r2_next    = data_table['R2'].iloc[i + 1]\n",
    "        rmse_curr  = data_table['RMSE'].iloc[i]\n",
    "        rmse_next  = data_table['RMSE'].iloc[i + 1]\n",
    "\n",
    "        r2_decrease = (r2_current - r2_next) / r2_current\n",
    "        rmse_increase = (rmse_next - rmse_curr) / rmse_curr\n",
    "\n",
    "        if (r2_decrease > R2_TRESHOLD) and (rmse_increase > RMSE_THRESHOLD):\n",
    "            return i\n",
    "    return len(data_table) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique selected features for each target model after thresholding\n",
    "fso_important_features = fso_table_final.groupby('SYNOPCode')[['RMSE','R2','Removed_Feature']].apply(lambda x: extract_selected_features(x))\n",
    "rfl_important_features = rfl_table_final.groupby('SYNOPCode')[['RMSE','R2','Removed_Feature']].apply(lambda x: extract_selected_features(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_feature_selection_generic(df, target, param_random_state=42):\n",
    "    \"\"\"\n",
    "    Iteratively remove the least important feature based on a RandomForestRegressor\n",
    "    with OOB estimates, until all features are removed.\n",
    "\n",
    "    Returns:\n",
    "      feature_removal_log: a dataframe with columns [Removed_Feature, RMSE, R2]\n",
    "      final_threshold_idx: the stopping index found by find_threshold(...)\n",
    "    \"\"\"\n",
    "    # Start with all columns except the target\n",
    "    remaining_features = [col for col in df.columns if col != target]\n",
    "\n",
    "    # Container for results at each iteration\n",
    "    results = []\n",
    "\n",
    "    while len(remaining_features) > 0:\n",
    "        # Train RF with OOB predictions\n",
    "        rf = RandomForestRegressor(\n",
    "            oob_score=True,\n",
    "            random_state=param_random_state\n",
    "        )\n",
    "        rf.fit(df[remaining_features], df[target])\n",
    "\n",
    "        oob_pred = rf.oob_prediction_\n",
    "        rmse = sqrt(mean_squared_error(df[target], oob_pred))\n",
    "        r2   = r2_score(df[target], oob_pred)\n",
    "\n",
    "        # Identify least important feature\n",
    "        importances = pd.Series(rf.feature_importances_, index=remaining_features)\n",
    "        least_important = importances.idxmin()\n",
    "\n",
    "        results.append({\n",
    "            \"Removed_Feature\": least_important,\n",
    "            \"RMSE\": rmse,\n",
    "            \"R2\": r2\n",
    "        })\n",
    "\n",
    "        # Remove from our working set\n",
    "        remaining_features.remove(least_important)\n",
    "\n",
    "    # Build a DataFrame\n",
    "    feature_removal_log = pd.DataFrame(results)\n",
    "    # The last iteration leaves 0 features in the model, so the final row is with the final feature removed\n",
    "    # You might want to keep the iteration that has N features. This is standard for \"backward\" style approach.\n",
    "\n",
    "    # Find threshold\n",
    "    final_threshold_idx = find_threshold(feature_removal_log)\n",
    "\n",
    "    return feature_removal_log, final_threshold_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------\n",
    "# 2) Method-2 (RFL → FSO) with Feature Selection & Re-tuning\n",
    "#    for the GENERIC case\n",
    "# -------------------------------------------------------\n",
    "def method2_rfl_to_fso_generic(train_data, test_data,\n",
    "                               fso_features_generic,    # list of original features for FSO\n",
    "                               rfl_features_generic,    # list of original features for RFL\n",
    "                               rfl_model_generic,       # trained RFL (generic) model\n",
    "                               param_grid,              # hyperparameter search space\n",
    "                               random_state=42):\n",
    "    \"\"\"\n",
    "    1) Use rfl_model_generic to predict RFL on the train set.\n",
    "    2) Create new train set with X_fso_train['RFL_pred'] added.\n",
    "    3) Perform feature selection on the new set of columns to predict FSO_Att.\n",
    "    4) Re-run hyperparameter tuning with the final subset of features.\n",
    "    5) Evaluate on test set: predict RFL, build final FSO feature set, get predictions, then compute correlation.\n",
    "    Returns:\n",
    "       final_correlation (float): Pearson correlation between RFL_pred and final FSO_pred on test\n",
    "       best_model (sklearn model): the final trained FSO model with new subset\n",
    "       final_features (list): the subset of features used in the final model\n",
    "       selection_table (DataFrame): the iteration log from feature selection\n",
    "    \"\"\"\n",
    "    # Initialize separate tables for FSO_Att and RFL_Att for each SYNOP code\n",
    "    target_features = ['FSO_Att', 'RFL_Att']\n",
    "    # 2.1) Predict RFL on the training set\n",
    "    X_rfl_train = train_data[rfl_features_generic]\n",
    "    rfl_train_pred = rfl_model_generic.predict(X_rfl_train)\n",
    "\n",
    "    # 2.2) Build the augmented feature set for FSO\n",
    "    fso_features = [col for col in train_data.columns if col not in target_features]\n",
    "    X_fso_train_aug = train_data[fso_features].copy()\n",
    "    X_fso_train_aug['RFL_pred'] = rfl_train_pred\n",
    "\n",
    "    # The target\n",
    "    y_fso_train = train_data['FSO_Att']\n",
    "\n",
    "    # We want to perform feature selection on X_fso_train_aug, targeting y_fso_train\n",
    "    # So let's combine them into a single DF for convenience:\n",
    "    df_for_selection = X_fso_train_aug.copy()\n",
    "    df_for_selection['FSO_Att'] = y_fso_train\n",
    "\n",
    "    selection_table, threshold_idx = perform_feature_selection_generic(\n",
    "        df_for_selection, target='FSO_Att', param_random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Extract the final subset of features from the iteration log\n",
    "    # 'Removed_Feature' is the feature removed at each iteration.\n",
    "    # Suppose the log has N steps if we started with M features, the final row is after removing all M features.\n",
    "    # We want the subset at \"threshold_idx\".\n",
    "    # Option 1: build from the start, removing features up to threshold_idx\n",
    "    removed_up_to_threshold = selection_table['Removed_Feature'].iloc[:threshold_idx+1].tolist()\n",
    "    # The original features in df_for_selection:\n",
    "    all_cols = [c for c in df_for_selection.columns if c != 'FSO_Att']\n",
    "    # Subset is everything except the removed features up to that index\n",
    "    final_features = [c for c in all_cols if c not in removed_up_to_threshold]\n",
    "\n",
    "    # 2.3) Re-run hyperparameter tuning on the final feature set\n",
    "    # Build X with final subset\n",
    "    X_fso_train_final = X_fso_train_aug[final_features]\n",
    "\n",
    "    rf_for_tuning = RandomForestRegressor(random_state=random_state)\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=rf_for_tuning,\n",
    "        param_distributions=param_grid,\n",
    "        n_iter=10,\n",
    "        cv=3,\n",
    "        random_state=random_state,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    search.fit(X_fso_train_final, y_fso_train)\n",
    "    best_params = search.best_params_\n",
    "\n",
    "    # Train the final FSO model with best_params\n",
    "    best_model = RandomForestRegressor(**best_params, random_state=random_state)\n",
    "    best_model.fit(X_fso_train_final, y_fso_train)\n",
    "\n",
    "    # 2.4) Evaluate on the test set\n",
    "    # Predict RFL on test\n",
    "    X_rfl_test = test_data[rfl_features_generic]\n",
    "    rfl_test_pred = rfl_model_generic.predict(X_rfl_test)\n",
    "\n",
    "    X_fso_test_aug = test_data[fso_features_generic].copy()\n",
    "    X_fso_test_aug['RFL_pred'] = rfl_test_pred\n",
    "\n",
    "    # Keep only the final features\n",
    "    X_fso_test_final = X_fso_test_aug[final_features]\n",
    "\n",
    "    # Predict FSO\n",
    "    fso_test_pred = best_model.predict(X_fso_test_final)\n",
    "\n",
    "    # Compute correlation\n",
    "    corr, _ = pearsonr(rfl_test_pred, fso_test_pred)\n",
    "\n",
    "    return corr, best_model, final_features, selection_table, threshold_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Final Pearson correlation (RFL_pred vs FSO_pred): 0.07276325964742988\n",
      "Final selected features: ['TemperatureMin', 'Particulate', 'AbsoluteHumidity', 'VisibilityMin', 'ParticulateMin', 'Temperature', 'Visibility', 'Distance', 'RFL_pred']\n",
      "Hyperparameter-tuned FSO model: RandomForestRegressor(min_samples_leaf=2, min_samples_split=10, n_estimators=50,\n",
      "                      random_state=42)\n",
      "Feature-selection iteration log:\n",
      "     Removed_Feature      RMSE        R2\n",
      "0              Time  0.907159  0.946120\n",
      "1  AbsoluteHumidity  1.100670  0.920682\n",
      "2       Particulate  1.245805  0.898385\n",
      "3    TemperatureMin  1.248534  0.897939\n",
      "4     VisibilityMin  1.241506  0.899085\n",
      "5          RFL_pred  1.235185  0.900110\n",
      "6    ParticulateMin  1.339286  0.882563\n",
      "7       Temperature  1.821647  0.782736\n",
      "8        Visibility  2.620088  0.550540\n",
      "9          Distance  3.754950  0.076859\n"
     ]
    }
   ],
   "source": [
    "correlation_method2, fso_model_method2, selected_feats_method2, fso_table, fso_threshold = method2_rfl_to_fso_generic(\n",
    "    train_data=train_data,\n",
    "    test_data=test_data,\n",
    "    fso_features_generic=fso_important_features['generic'],\n",
    "    rfl_features_generic=rfl_important_features['generic'],\n",
    "    rfl_model_generic=rfl_models['generic'],  # your pre-trained RFL generic model\n",
    "    param_grid=param_grid,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Final Pearson correlation (RFL_pred vs FSO_pred):\", correlation_method2)\n",
    "print(\"Final selected features:\", selected_feats_method2)\n",
    "print(\"Hyperparameter-tuned FSO model:\", fso_model_method2)\n",
    "print(\"Feature-selection iteration log:\\n\", fso_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_feature_selection(\n",
    "    rfl_table,\n",
    "    fso_table,\n",
    "    rfl_threshold=None,\n",
    "    fso_threshold=None,\n",
    "    title=\"Feature Selection Performance\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Generates side-by-side plots of RMSE and R² for RFL_Att and FSO_Att\n",
    "    as a function of removed features in feature selection.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    rfl_table : pd.DataFrame\n",
    "        DataFrame containing columns:\n",
    "            - 'Removed_Feature'\n",
    "            - 'RMSE'\n",
    "            - 'R2'\n",
    "        for the RFL_Att feature selection iteration.\n",
    "        \n",
    "    fso_table : pd.DataFrame\n",
    "        DataFrame containing columns:\n",
    "            - 'Removed_Feature'\n",
    "            - 'RMSE'\n",
    "            - 'R2'\n",
    "        for the FSO_Att feature selection iteration.\n",
    "        \n",
    "    rfl_threshold : int, optional\n",
    "        The index from feature selection to mark on RFL plot \n",
    "        (e.g., from find_threshold(...)). If None, no vertical line is drawn.\n",
    "        \n",
    "    fso_threshold : int, optional\n",
    "        The index from feature selection to mark on FSO plot.\n",
    "        If None, no vertical line is drawn.\n",
    "        \n",
    "    title : str, optional\n",
    "        A main title for the figure. Defaults to \"Feature Selection Performance\".\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    fig : matplotlib.figure.Figure\n",
    "        The created figure object.\n",
    "    axes : np.ndarray of matplotlib.axes.Axes\n",
    "        The array of subplot axes ([ax_rfl, ax_fso]).\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "\n",
    "    # --------------------------\n",
    "    # Left Plot: RFL_Att\n",
    "    # --------------------------\n",
    "    axes[0].plot(\n",
    "        rfl_table['Removed_Feature'],\n",
    "        rfl_table['RMSE'],\n",
    "        label=\"RMSE (dB)\",\n",
    "        color=\"blue\"\n",
    "    )\n",
    "    axes[0].set_ylabel(\"RMSE (dB)\", color=\"blue\")\n",
    "    axes[0].tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    ax_r4 = axes[0].twinx()\n",
    "    ax_r4.plot(\n",
    "        rfl_table['Removed_Feature'],\n",
    "        rfl_table['R2'],\n",
    "        label=\"R²\",\n",
    "        color=\"red\"\n",
    "    )\n",
    "    ax_r4.set_ylabel(\"R²\", color=\"red\")\n",
    "    ax_r4.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "    # Mark threshold if given\n",
    "    if rfl_threshold is not None and 0 <= rfl_threshold < len(rfl_table):\n",
    "        axes[0].axvline(\n",
    "            x=rfl_threshold,\n",
    "            color=\"green\",\n",
    "            linestyle=\"--\",\n",
    "            label=\"1% R² Threshold\"\n",
    "        )\n",
    "\n",
    "    axes[0].set_title(\"(a) RFL_Att\")\n",
    "    axes[0].set_xticklabels(rfl_table['Removed_Feature'], rotation=90)\n",
    "\n",
    "    # --------------------------\n",
    "    # Right Plot: FSO_Att\n",
    "    # --------------------------\n",
    "    axes[1].plot(\n",
    "        fso_table['Removed_Feature'],\n",
    "        fso_table['RMSE'],\n",
    "        label=\"RMSE (dB)\",\n",
    "        color=\"blue\"\n",
    "    )\n",
    "    axes[1].set_ylabel(\"RMSE (dB)\", color=\"blue\")\n",
    "    axes[1].tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "\n",
    "    ax_f2 = axes[1].twinx()\n",
    "    ax_f2.plot(\n",
    "        fso_table['Removed_Feature'],\n",
    "        fso_table['R2'],\n",
    "        label=\"R²\",\n",
    "        color=\"red\"\n",
    "    )\n",
    "    ax_f2.set_ylabel(\"R²\", color=\"red\")\n",
    "    ax_f2.tick_params(axis=\"y\", labelcolor=\"red\")\n",
    "\n",
    "    # Mark threshold if given\n",
    "    if fso_threshold is not None and 0 <= fso_threshold < len(fso_table):\n",
    "        axes[1].axvline(\n",
    "            x=fso_threshold,\n",
    "            color=\"green\",\n",
    "            linestyle=\"--\",\n",
    "            label=\"1% R² Threshold\"\n",
    "        )\n",
    "\n",
    "    axes[1].set_title(\"(b) FSO_Att\")\n",
    "    axes[1].set_xticklabels(fso_table['Removed_Feature'], rotation=90)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'generic'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'generic'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m rfl_threshold \u001b[38;5;241m=\u001b[39m find_threshold(rfl_table_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneric\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plot_feature_selection(\n\u001b[1;32m      4\u001b[0m     rfl_table\u001b[38;5;241m=\u001b[39mrfl_table_final[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeneric\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m      5\u001b[0m     fso_table\u001b[38;5;241m=\u001b[39mfso_table,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m     title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature Selection Performance - Generic Model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/core/frame.py:4090\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4088\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4089\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4090\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   4091\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4092\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/tf/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'generic'"
     ]
    }
   ],
   "source": [
    "rfl_threshold = find_threshold(rfl_table_final['generic'])\n",
    "\n",
    "fig, axes = plot_feature_selection(\n",
    "    rfl_table=rfl_table,\n",
    "    fso_table=fso_table,\n",
    "    rfl_threshold=rfl_threshold,\n",
    "    fso_threshold=fso_threshold,\n",
    "    title=\"Feature Selection Performance - Generic Model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "umlt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
